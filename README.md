---
title: MVP Consultor√≠a RAG para Discursos de Javier Milei
emoji: ü§ñ
colorFrom: blue
colorTo: green
sdk: streamlit
sdk_version: "1.28.1"
app_file: app.py
pinned: false
---

# MVP Consultor√≠a RAG para Discursos de Javier Milei

LINK: https://huggingface.co/spaces/manuelcpv92/mvp_ag_optimizado

Este proyecto es un M√≠nimo Producto Viable (MVP) de un sistema de Generaci√≥n Aumentada por Recuperaci√≥n (RAG) dise√±ado para consultar discursos oficiales y transcripciones de audios del Presidente Javier Milei. Utiliza t√©cnicas de procesamiento de lenguaje natural para permitir consultas precisas sobre el contenido de sus discursos p√∫blicos y transcripciones.

## Descripci√≥n

El sistema extrae autom√°ticamente discursos oficiales desde el sitio web de Casa Rosada y permite la adici√≥n manual de transcripciones de audios, procesa todo el contenido y lo indexa en una base de datos vectorial. Actualmente incluye discursos oficiales y 3 transcripciones de audios agregadas. Luego, mediante un modelo de lenguaje (Google Gemini), responde preguntas espec√≠ficas basadas √∫nicamente en la informaci√≥n contenida en estos documentos.

## Funcionalidades

- **Extracci√≥n autom√°tica de discursos**: Scraping inteligente del sitio web oficial de Casa Rosada para obtener discursos recientes.
- **Adici√≥n manual de transcripciones**: Incorporaci√≥n de transcripciones de audios para enriquecer el corpus (actualmente incluye 3 transcripciones agregadas).
- **Procesamiento de texto**: Limpieza y estructuraci√≥n del contenido de los discursos y transcripciones.
- **Indexaci√≥n vectorial**: Creaci√≥n de embeddings multiling√ºes para b√∫squeda sem√°ntica eficiente.
- **Consulta RAG**: Sistema de preguntas y respuestas que combina recuperaci√≥n de informaci√≥n con generaci√≥n de respuestas.
- **Interfaz web**: Aplicaci√≥n Streamlit intuitiva para realizar consultas.
- **Fuentes verificadas**: Cada respuesta incluye referencias a los discursos o transcripciones espec√≠ficos utilizados.

## Arquitectura del sistema RAG

El sistema RAG implementado sigue un flujo est√°ndar de Generaci√≥n Aumentada por Recuperaci√≥n:

1. **Ingesta de datos**: Extracci√≥n autom√°tica de discursos desde el sitio web oficial de Casa Rosada mediante scraping y adici√≥n manual de transcripciones de audios.
2. **Procesamiento de texto**: Limpieza, tokenizaci√≥n y divisi√≥n en chunks (fragmentos) para optimizar la indexaci√≥n.
3. **Indexaci√≥n vectorial**: Conversi√≥n de los chunks a embeddings num√©ricos utilizando un modelo de embeddings multiling√ºe.
4. **Almacenamiento**: Persistencia de los embeddings en una base de datos vectorial para b√∫squedas eficientes.
5. **Consulta**: Procesamiento de la pregunta del usuario, b√∫squeda de chunks relevantes y generaci√≥n de respuesta basada en el contexto recuperado.

### Diagrama de flujo

```
Scraping de discursos (generate_corpus.py) --> Procesamiento de texto --> Creaci√≥n de embeddings (mvp_rag.py) --> Almacenamiento vectorial
Adici√≥n de transcripciones (add_transcripts.py) --> Procesamiento de texto
Consulta del usuario (app.py) --> B√∫squeda de documentos relevantes --> Generaci√≥n de respuesta --> Respuesta con fuentes
```

## Decisiones de dise√±o

- **Separaci√≥n de ingesta**: El proceso de scraping y generaci√≥n del corpus se realiz√≥ en un script independiente (`generate_corpus.py`) para mantener la modularidad, facilitar pruebas y permitir actualizaciones del dataset sin afectar el n√∫cleo del sistema RAG.
- **Modelo de embeddings**: Se seleccion√≥ `intfloat/multilingual-e5-large` por su excelente rendimiento en tareas multiling√ºes, especialmente en espa√±ol, y su capacidad para capturar sem√°ntica contextual en textos largos.
- **Modelo de lenguaje**: Google Gemini 2.5 Flash fue elegido por su velocidad de respuesta, bajo costo y capacidad nativa para procesar consultas en espa√±ol sin necesidad de fine-tuning adicional.
- **Base de datos vectorial**: ChromaDB se utiliz√≥ por su simplicidad de integraci√≥n con Python, persistencia local y soporte eficiente para b√∫squedas de similitud coseno.
- **Estrategia de chunking adaptativa**: Se implement√≥ una clasificaci√≥n autom√°tica de documentos basada en su longitud para optimizar el chunking. Documentos largos (>5000 caracteres, discursos oficiales) usan chunk_size=1000 con overlap=200, mientras que documentos cortos (<1000 caracteres, transcripciones) usan chunk_size=300 con overlap=50. Longitudes intermedias usan la configuraci√≥n fallback de 500/50, preservando la coherencia contextual mediante separadores naturales.
- **Interfaz de usuario**: Streamlit se implement√≥ para una interfaz web simple y accesible, priorizando la usabilidad sobre complejidad, adecuado para un MVP.
- **Fuentes verificadas**: Se incluy√≥ un sistema de referencias para cada respuesta, asegurando transparencia y permitiendo verificaci√≥n de la informaci√≥n utilizada.

## C√≥mo Usar la App

### Requisitos Previos

- Python 3.8+
- Clave de API de Google (Google AI Studio)
- Conexi√≥n a internet para scraping inicial

### Instalaci√≥n

1. Clona o descarga el proyecto.
2. Instala las dependencias:
   ```
   pip install -r requirements.txt
   ```
3. Configura la variable de entorno:
   ```
   export GOOGLE_API_KEY="tu_clave_api_aqui"
   ```
   O en Windows:
   ```
   set GOOGLE_API_KEY=tu_clave_api_aqui
   ```

### Ejecuci√≥n

1. Ejecuta la aplicaci√≥n:
   ```
   streamlit run app.py
   ```
2. Abre el navegador en la URL proporcionada (generalmente http://localhost:8501).
3. Espera a que se inicialice el sistema RAG (puede tomar unos minutos en la primera ejecuci√≥n).
4. Ingresa tu pregunta en el campo de texto y haz clic en "Consultar".
5. Revisa la respuesta y las fuentes consultadas.

### Ejemplos de Consultas

- "¬øQu√© dice Milei sobre la econom√≠a?"
- "¬øCu√°les son las prioridades del gobierno seg√∫n los discursos?"
- "¬øQu√© menciona sobre educaci√≥n?"

## Despliegue en HF Spaces

https://huggingface.co/spaces/manuelcpv92/Consultor_Virtual_RAG_de_Politicas_y_Discursos_de_Milei

### Preparaci√≥n

1. Crea una cuenta en [Hugging Face](https://huggingface.co).
2. Crea un nuevo Space con la opci√≥n "Streamlit".
3. Sube los archivos del proyecto (app.py, mvp_rag.py, requirements.txt).
4. Para el vectorstore, tienes dos opciones:
   - **Regenerar en HF**: El sistema scrapear√° y crear√° el vectorstore al iniciar (recomendado para datos actualizados).
   - **Subir chroma_db**: Sube la carpeta chroma_db pre-generada (√∫til para consistencia).

### Configuraci√≥n de Secrets

En la configuraci√≥n del Space, agrega el secret:
- `GOOGLE_API_KEY`: Tu clave de API de Google.

### Notas sobre Despliegue

- El scraping inicial puede tomar tiempo; considera aumentar el timeout si es necesario.
- HF Spaces tiene l√≠mites de recursos; para uso intensivo, considera instancias pagas.
- El vectorstore se regenera en cada reinicio; para persistencia, implementa almacenamiento en HF Datasets.
- Aseg√∫rate de que el modelo de embeddings sea compatible con los recursos de HF.

## Notas T√©cnicas

- Utiliza ChromaDB para almacenamiento vectorial.
- Embeddings multiling√ºes con `intfloat/multilingual-e5-large`.
- Modelo LLM: Google Gemini 2.5 Flash.
- Solo utiliza informaci√≥n de discursos oficiales verificados y transcripciones de audios agregadas.
- El sistema est√° optimizado para consultas en espa√±ol.

## Limitaciones

- Depende de la disponibilidad del sitio web de Casa Rosada.
- Respuestas limitadas a la informaci√≥n presente en los discursos indexados.
- No incluye discursos anteriores a la implementaci√≥n del scraper ni transcripciones no agregadas manualmente.

## Estructura de Archivos

```
PROYECTO C/
‚îú‚îÄ‚îÄ app.py                 # Aplicaci√≥n principal de Streamlit para la interfaz web
‚îú‚îÄ‚îÄ mvp_rag.py            # M√≥dulo principal con l√≥gica RAG, embeddings y configuraci√≥n del sistema
‚îú‚îÄ‚îÄ generate_corpus.py    # Script para scraping y generaci√≥n autom√°tica del corpus de discursos
‚îú‚îÄ‚îÄ add_transcripts.py    # Script para agregar transcripciones manualmente al corpus
‚îú‚îÄ‚îÄ mi_corpus.json        # Archivo JSON que contiene el corpus completo de discursos procesados
‚îú‚îÄ‚îÄ requirements.txt      # Lista de dependencias de Python con versiones espec√≠ficas
‚îú‚îÄ‚îÄ chroma_db/            # Directorio de la base de datos vectorial ChromaDB
‚îÇ   ‚îú‚îÄ‚îÄ chroma.sqlite3    # Base de datos SQLite para metadatos
‚îÇ   ‚îú‚îÄ‚îÄ [uuid]/           # Directorio con archivos de datos vectoriales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data_level0.bin
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ header.bin
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ length.bin
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ link_lists.bin
‚îî‚îÄ‚îÄ README.md             # Documentaci√≥n del proyecto
```

## Dependencias y Versiones

El proyecto utiliza las siguientes bibliotecas principales:

- **LangChain (0.1.20)**: Framework para construir aplicaciones con LLMs
- **LangChain Google GenAI**: Integraci√≥n con modelos de Google Gemini
- **ChromaDB**: Base de datos vectorial para almacenamiento de embeddings
- **Sentence Transformers**: Para generar embeddings multiling√ºes con `intfloat/multilingual-e5-large`
- **Streamlit (1.28.1)**: Framework para la interfaz web
- **BeautifulSoup4**: Para parsing HTML en el scraping
- **Requests**: Para realizar peticiones HTTP
- **Pandas**: Para manipulaci√≥n de datos durante el procesamiento

## Decisiones T√©cnicas Detalladas

### Arquitectura RAG
- **Retriever**: Usa Maximum Marginal Relevance (MMR) con k=5 documentos principales y fetch_k=15 para diversidad
- **Chunking adaptativo**: Clasificaci√≥n autom√°tica por longitud - largos (>5000 chars): 1000/200, cortos (<1000 chars): 300/50, intermedios: 500/50, separados por p√°rrafos naturales
- **Embeddings**: Modelo `intfloat/multilingual-e5-large` optimizado para espa√±ol y contexto largo
- **LLM**: Gemini 2.5 Flash con temperatura 0.1 para respuestas consistentes
- **Memoria**: ConversationBufferMemory para mantener contexto en conversaciones

### Procesamiento de Datos
- **Scraping**: Automatizado desde sitio oficial de Casa Rosada
- **Limpieza**: Eliminaci√≥n de HTML, normalizaci√≥n de texto
- **Metadata**: Conserva t√≠tulo, fecha y URL de cada discurso
- **Persistencia**: Corpus en JSON + vectorstore en ChromaDB local

### Interfaz y UX
- **Streamlit**: Elegido por simplicidad y deployment en HF Spaces
- **Historial**: Mantiene conversaci√≥n completa en session state
- **Fuentes**: Expansores para mostrar fragmentos relevantes con metadata

## Desarrollo y Contribuci√≥n

### Configuraci√≥n del Entorno de Desarrollo

1. Clona el repositorio:
   ```
   git clone <url-del-repositorio>
   cd PROYECTO\ C
   ```

2. Crea un entorno virtual:
   ```
   python -m venv venv
   # En Windows:
   venv\Scripts\activate
   # En Linux/Mac:
   source venv/bin/activate
   ```

3. Instala dependencias:
   ```
   pip install -r requirements.txt
   ```

4. Configura la API key:
   ```
   export GOOGLE_API_KEY="tu_clave_api_aqui"
   # En Windows:
   set GOOGLE_API_KEY=tu_clave_api_aqui
   ```

### Ejecutar Componentes Individuales

- **Generar corpus desde web**: `python generate_corpus.py`
- **Agregar transcripciones manualmente**: `python add_transcripts.py`
- **Ejecutar aplicaci√≥n web**: `streamlit run app.py`
- **Probar sistema RAG**: Importar funciones desde `mvp_rag.py`

### Gu√≠as de Contribuci√≥n

1. **Fork** el proyecto
2. Crea una **rama** para tu feature: `git checkout -b feature/nueva-funcionalidad`
3. **Commit** tus cambios: `git commit -m 'Agrega nueva funcionalidad'`
4. **Push** a la rama: `git push origin feature/nueva-funcionalidad`
5. Abre un **Pull Request**

### √Åreas de Mejora Sugeridas

- Implementar tests unitarios para funciones cr√≠ticas
- Agregar logging detallado para debugging
- Optimizar rendimiento del vectorstore para datasets m√°s grandes
- Implementar cache para respuestas frecuentes
- Mejorar el prompt engineering para respuestas m√°s precisas
- Agregar soporte para m√∫ltiples idiomas
- Implementar evaluaci√≥n autom√°tica de calidad de respuestas

### Reportar Issues

Para reportar bugs o solicitar nuevas funcionalidades:

1. Verifica que el issue no exista ya
2. Proporciona detalles completos: pasos para reproducir, entorno, logs de error
3. Incluye ejemplos de consultas que fallan o comportamientos inesperados
4. Etiqueta apropiadamente (bug, enhancement, question)

## Licencia

Este proyecto es de c√≥digo abierto. Consulta el archivo LICENSE para m√°s detalles.

## üë§ Grupo

**[Velasquez Christian]**  
- Email: 94721647@ifts24.edu.ar

- **[Sanchez Carlos]**  
- Email: 18253606@ifts24.edu.ar

**Trabajo Integrador - NLP**  
Fecha de realizaci√≥n: [20/11/25]
---





